[{"location":"关于/我","text":"本博客，也是MdRest的引擎创建，你也可以将它当作mdrest示例。\n关于我 github: https://github.com/ti\n","title":"又一个程序员的一亩三分地\n"},{"location":"readme","text":"采用 MdRest 引擎编写, 编辑文章到 master 分之，十分钟就会被更新一次。\n","title":"个人博客\n"},{"location":"项目/mdrest","tags":["golang","博客","markdown"],"text":"从Markdown建站，几乎成了整个技术圈博客标配，但是Markdown的技术存在很多限制，搜索下目前Markdown博客引擎你会发现，所有的博客引擎定制化不是很高，并且目前很多很流行的博客引擎都不太完善。目前流行的Markdown引擎如下，这些东西缺点显而易见。\n流行的markdown引擎\n对于一个技术流而言，这些博客可拓展性太差，对于一个非技术流而言，操作太复杂。一直想写一个restful风格的Markdown引擎，一个偶然的机会，工作中需要改版开发者中心的文档系统，于是一个restful风格的Markdown引擎就应运而生了，耗时：5天。这比我想象的时间少了很多，于是就将其作为一个库进行开源。\nGithub地址：https://github.com/ti/mdrest\n最终展示效果：\n 博客： http://nanxi.li 文档中心：http://accounts.cug.edu.cn/apps/docs.html  先上几张图，说明Markown最终效果，当然，如果你是在我的博客中阅读这篇文章的话，博客本身就是最好的效果展示。\n主页\n全文搜索\n正文排版\n标签页面\n MdRest 本身不做博客，它只是数据生成器。你无需对现有的md文件做任何更改，就可以轻松地将她们转换为可索引，结构化，免服务器，低成本的json数据。md文档的数据化，给前端展示带来无限可能，它可以是文档中心，可能是普通博文，也可能是录音，视频，相册，将数据与展示解绑才能更多可能。\n 特性 1. 自由的目录结构和文章内容 自由的目录结构，你的博客目录可以是这个样子，所有的目录安排，图片资源摆放，完全可以按照你自己的喜好和规则，无需按照特定的约束进行。markdown rest引擎会将所有图片资源转换为以根目录为主目录绝对路径。也意味着，如果你的文章在git中浏览是正常的，那在博客中也会是正常的，无需对文章做转换。\n目录结构\nsample_docs ├── Simple Article.md ├── YAML Article.md ├── _DraftArticle.md ├── first dir │ ├── Hello word.md │ └── img │ └── logo.png └── second\\ dir └── Hello\\ word.md  文档结构：\n# Hello world 这篇文章会自动识别文章标题，自动截取文章简介，自动转换图片相对流经。 ![img1](../folder2/hello.png) ![img2](folder2/hello.png) 查看关联的其他文章, [other reference markdown](../folder2/reference.md)  2. 智能的文档属性 如果你用过其他的博客引擎，可能会要求你的博客是下面这个样子的。\n--- title: Hello world author: leenanxi catalog: blog tags: [tag1, tag2] date: 2016-12-29 draft: true --- # Hello world This is content  Mdrest对Markdown的格式没有要求，你的文章可以是下面这个样子。文章的标题，创建日期，catalog 都可以自动生成。标题生成的的优先级是：yaml -\u0026gt; 第一个# -\u0026gt; 文件名。 草稿文章标题可以是 _filename.md\n# Hello world This is content  3. 自由的JSON输出 MdRest支持任何格式的Yaml标签，它会将您的Ymal标签转换为JSON，例如您的文章可以是下面这个样子的。大多数使用markdown博客引擎主题的时候会使用html和js修改主题的很多功能，mdrest给开发者最大的修改自由，允许完全自由的输出格式。\n--- video: /videos/hello_word.mp4 medias: [video1.mp4, video2.mp4,pic1.jpg] other1: name: \u0026quot;name\u0026quot; x1: [3, 4] --- # Hello world This is content  4. 拓展Markdown渲染 （模仿简书） 我们的博客中图片难免需要插入图片标注，之前很多人的做法是给图片下面添加一个段落或块引用来进行，其实Markdown原生支持 ![img](path.png \u0026quot;title\u0026quot;) 这样的形式，mdrest会自动将title作为题注，进行html渲染，当然，您可以在markdown中使用html进行更复杂的操作。\n# Hello world ![无印良品](../imgs/wulinliangpin.png \u0026quot;无印良品LOGO\u0026quot;)  \n5. 极简的前端组件。  不使用jQuery 不使用任何JS框架 纯粹的html5开发   目前的博客前端完全模仿angularjs的路由和API风格，但是整体架构却使用原生JS自行编写，因此体积很小，前端所有的业务逻辑JS和框架JS加起来只有：83.1 KB， 作为对比，流行的框架体积如下，可以看到应用的全部代码都比任何一个js库小。\n    Library/Framework size (min)     jQuery 3.2 86kb   React 147kb/**   Angular 1 159kb/235kb   Polymer 222kb/302kb   Aurelia 287kb/352kb   Ember 433kb   Angular 2 623kb/1023kb      大部分小应用场景下，我们不需要任何框架来开发前端组件，体积，效率，自由度各方面都有影响。了解基础的js知识 + 各框架基本原理，可以给我们的应用带来意想不到的时间和空间上的收获。\n 写在最后 推荐使用typora作为markdown的主要编辑工具，可以给你带来更简单的输入体验。\n","title":"MdRest 关于Markdown博客，你所期望的都在这里\n"},{"location":"设计/不存在的“白”","tags":["设计"],"text":"1、‘白’这样的东西是不存在的 漂白的骨头让我们与死亡相连，但奶和蛋的白，又对我们述说着生命，衣服的白，又让我们感觉到了温暖与舒适。母乳的哺育对所有的哺乳动物来说都是重要行为，但无论动物还是人类，所有的乳汁都是白色的。大多数蛋也都是白色的，无论下这些蛋的鸟是什么颜色，白鸟下白蛋，蓝鸟也是，黑鸟也是，蛇也是，甚至鳄鱼也是。真正的生命居于白之中。蛋壳就像是构成这个世界与另一个世界边界的膜。当其打开，出来的就不在是白的，而是该种动物之本色。\n 世间本没有“白”，但我们经常感觉到了“它”的存在，在这个现实世界中，白总是被污染的、不纯的。它只是一道痕迹，一道其指向本源的标志而已,我们可能感觉到了白，但那只是一种幻觉。\u0026ldquo;白”\u0026rdquo;包含了所有颜色，又褪去了所有颜色，是负熵的极限，是生命的起始，是信息的“边缘”。当我们获得了与“白”的这种联系，我们的世界发出的光就更亮了，投出的影也就更深了。\n 白的纯洁是短暂的，因为他很容易被玷污，也正是人们意识到了美的转瞬即逝，才异常珍惜，这也就是人的本性吧，即得不到的才是最美的，是不是有点贱啊，嘿嘿嘿。\n2、还原颜色的本质 一个简单的色彩在不同的肌理的表现下会传递不同的“触知”，不同的“触知”会传递不同的情绪，这些感受共同组成了色彩丰富的“容纳性”。\n 颜色不仅仅是视觉的，它与人的全部感知是相关的。\n 世界就像一场想象得到的所有颜色的奢华盛宴。树木的新鲜、水面的反光、水果的明丽、熊熊篝火的闪亮，这些颜色中的任何一种对我们来说都是亲切的。因为它们都已经不仅仅是一种颜色了，每种颜色背后都有着历史，有着数不清的故事，轻而易举地就与人们完成了信息交流，很容易就引起了共鸣。相对的，现在设计中运用的五花八门的电脑颜色，除了好看的感觉外，其他什么都不能表达，所以实际上这些颜色是无效的，所谓的蓝色代表忧郁，白色代表高贵，没有载体，何来代表性。\n 设计师不是为了要把一些日用品或者一些平面的东西设计的好看，他们其实是要在努力的设计出一种环境，在这个环境里面，我们人跟人之间产生交流，沟通。\n ","title":"不存在的“白”\n"},{"location":"设计/读懂《设计的觉醒》","tags":["设计","日本"],"text":"《设计的觉醒》作者田中一光用平实的语言向我们娓娓道说了他这一生设计思考的觉醒过程。 田中一光， 是日本著名的设计师，是平面设计领域的教父级人物， 在书中我们可以详尽的体会到他的生活、设计构思、以及对整个设计界的认知，而且读了那本书之后，感觉不只是在讲日本近代设计理论，而是在讲一个二战后自我奋发觉醒的国家，他们探究着日本人真正的需求，真正的设计，反思设计与社会的碰撞和 带来的影响。跟着这本书的文字，让我们进入了设计解决现实问题的世界，感受到设计工作与生活间的共鸣和无处不在的设计灵感， 田中一光用他一生坎坷的经历以及辉煌的设计历程来诠释设计思考的觉醒过程。 现在，设计日益为大家所重视，同时又出现了各种困惑，本书试图让大家通过田中一光的设计思考，去了解那些平日里司空见惯的、在普通不过的日常我们其实是多么“不了解”，进而让我们站在新知识的肩膀上，邂逅新鲜的“设计”，让“设计”在自己的身体中觉醒。\n1.无印良品 无印良品LOGO\n\n 早晨，你可以穿着“无印良品”的睡袍，在“无印良品”的床上醒来，然后用“无印良品”的牙刷刷牙，喝“无印良品”咖啡机煮出来的咖啡，坐在“无印良品”的沙发上，听“无印良品”的音响送出音乐……所有的一切，简简单单，不矫揉，不造作，却又认真贴切地照顾到我们的生活需要。对，就是这样，无印良品从最初的几十种商品发展到今日约5000种商品，从牙刷到汽车（是的，汽车，与日产合作的Muji March），食物到电器，从眼镜铺到Meal Muji餐厅，从实品商店到网络世界中的Muji.Net，成为完整的生活提案店，从早到晚生活中的一切都可以是无印良品的。\n \n 在无印良品专卖店里，除了红色的“MUJI”方框，顾客几乎看不到任何鲜艳的颜色，大多数产品的主色调都是白色、米色、蓝色或黑色。以前也听过无印良品，我一直对无印良品很好奇，其实也是最熟悉的。 “无印良品(MUJI)”创始于日本，其本意是“没有商标与优质”。虽然极力淡化品牌意识，但它遵循统一设计理念所生产出来的产品无不诠释着“无印良品”的品牌形象，它倡导自然、简约、质朴的生活方式， 那种简单的设计所带来的人类新的认知，很简单很干净，是我喜欢的那种设计，我一直就喜欢干净的设计，不复杂。其实越简单反而越难。\n ​\n2.永远的琳派 \n 众多日本画的流派中，琳派是充满日本特色而且比较特别的一派。许多流派如狩野派都受到中国的水墨画技法的影响，琳派的基础则是建立于日本传统的《大和绘》之上，具有非常强的装饰性，画面设计华丽。只要看一看琳派的著名作品《风神雷神图屏风》，便能对其特色一目了然。琳派以俵屋宗达、尾形光琳和酒井抱一为代表，在日本绘画史上绽放了灿烂的光辉。\n \n 田中一光说：“我尽量和琳派保持一定的距离，因为我怕有被琳派的这种伟大的生命力吞没的危险，它让我直想躺在它的怀抱里。\n ” 它既像温柔的琴声，又像是日本传统的戏剧”能“那尖锐的笛子声，有一种让日本人的血液沸腾起来的东西。那是典雅、自由、豁达而灿烂的世界，它并不炫耀自己的美质，展现像早春的阳光似的温暖世界。 琳派的自然描写一边隐藏着自然生态具有的丑陋侧面，一边通过明亮颜色的滤器，将其投影、转移到宫廷式的典雅舞台上。肉感通过形式化被净化，月亮因秋草增添趣味，深深的铭刻在人的心里，而这些表现又通过理性的批评精神被研究和创新。功能一点都没有被美质损坏，反而以用法本身起了让作品唤起新的美感的核心作用。 ​\n3.每日设计赏  \n战后的日本百废待兴，为了经济的迅速发展，创设了每日设计赏。在作者看来，每日设计赏的成长，也是日本经济成长和社会变动的一个缩影。 每日设计赏从1955年就开始举办。如果说五六十年代的每日设计赏是设计的“功劳奖”，那七十年代就是“作品奖”，而八十年代则是“作家奖”。从这个明显的特征可以看出，日本设计界发生了巨大的变化，设计的成熟度显而易见。 从此奖项最初创设的1955年至1960年代末的十五年间，正是日本设计的启蒙时期。最初在获奖理由的抬头里多是运动、贡献和确立等词语，而这些词语在八十年代以后就很难见到踪影了。由此我们可以感觉到，这个奖项在创办之初其实是具有启蒙和鼓励之意的。 ​\n4.二战后的日本  日本，常常被认为是一个精神十足的国家，因为日本人拥有贪婪的好奇心和旺盛的咀嚼力。在日本，中学生没有不知道莎士比亚的，因为《罗密欧与朱丽叶》和《哈姆雷特》早已不知上演了多少次。战败后的35年里，日本人从欧美学到了很多东西。不仅在科技上，在文化思想领域也勤奋地吸收着欧美的长处. \u0026lsquo;设计来源于生活，并应用于生活。二战后的日本为了孕育出新的生活文化，贪婪的吸收着欧美的生活文化，不管能否消化，西安吞下去再说，人民生活中处处存在“和与洋”的结合，筷子和叉子、和服和西服、和室和西室房间、日本画和西洋画等等。在两者的相遇过程中，曾有过痛苦的经历和操作失误，也有过不可思议的体验。不少日本设计师把欧美的现代主义原样照搬过来，但这些在具有浓郁日本文化的土地上发育不良，这就是促使他们开始反思到底什么样的东西才是“日本的”。 今天的日本，其实是以东西方两条腿在前进，这样一对矛盾体，却反而使日本显现出令世界感到惊叹的无限活力。 ​\n5.东方和西方的金色感觉  对于欧洲人来说，不论上流阶级还是贫民百姓，不论民主主义还是社会主义，他们对金色都有着共同的执着和信仰，不管是列宁广场的俄罗斯国立美术馆，还是Piotr宫殿的黄金喷水雕像，当然还有维也纳的国立美术历史博物馆，巴黎的歌剧院，伦敦的女王广场，都是在黄金豪华的世界里展开他们多彩的艺术展出和演出的。\n\n 而对于日本，金色并不是炫耀权力、象征财富的东西，而是被日本人更多的作为一种带有神秘感的色彩，夕阳西下，稻穗泛着金光，也许这就是日本膜拜金色的开端。他们喜欢在金箔上厚厚地涂上蓝绿色或者各种蓝色，形成鲜明的对比，将神圣和华丽在感官上完美地平衡。\n ​\n6.过剩的包装  一个非常漂亮的瓶子，打开一看发现里面只有几个用真空包装的泡菜，还有那些特意一个一个放入厚纸板箱的罐头，以及为了不那么快被扔掉而用金色或者银色印刷的豪华外包装盒等，各式各样华丽的礼品外表包裹着内里的空虚，它们一点也传达不了送礼人的用心。那原本送礼物的美好用心，就这样被商业主义歪曲，变成了这种让人一看就很豪华的表演，而实质上更显现出内心的贫乏。\n 我相信那些头脑灵活的工厂以及商店老板不可能对这些资源浪费毫无觉察，消费者也是很聪明的，然而这种现象却在大家默许的惰性推动下保持着一种均衡，没有任何一个群体提出抗议，一切都在依旧进行着，真是可悲可叹。 ​\n7.文字与设计 \n 如果说插图和图片是一首歌曲，那么文字就是伴奏。歌曲会因为伴奏而变得更加优美，而伴奏不可能因为歌曲而变得好听。以前的平面设计中，文字与非文字的关系非常简单，文字一直从属于画面，但对画面产生不了影响，基本就是将斗大的字粗糙的印在画面之中。\n 但在经历了鲁巴林和杜鲁夫斯曼的创作后，文字第一次成为真正的主角，以穆勒-布洛克曼为中心的瑞士平面运动也在此加快了前进的步伐。对于日本，其影响不仅没有停留在表面的造型上，而且渐渐出现在了以逻辑为主的编排设计。可以这样理解，没有文字的海报是存在的，因为超语言“一看即懂”的视觉沟通是存在的，但总给人一种缺乏现实感，很容易失去社会性，从而只属于作者的个人世界。文字则不同，即使离开了设计它也依然可以作为语言独立的存在。但在作品中，如果文字偏离了本意，这个设计作品就难逃沦为废纸的宿命，文字的主角光环显而易见。 由此，文字与设计作品的交叉很难用一句话来概括的，但即使为文字设计编排倾尽灵魂和心血，也是非常值得的，现在报纸杂志、电视、海报、包装等广阔的世界都充满了文字与设计，可以说我们的世界都被文字包围着。 ​\n8.Loft店铺 \n作者田中一光写到：“今年入春以来，我就一直沉浸在店铺设计和视觉策划的工作中。众所周知，Loft是以新潮而丰富的货品著称的，它拥有将近二十万种日用杂货。所以自1987年初创以来，很快就成为了东京的知名店铺。据关西的一些报纸报道，这次的Loft大阪梅田店，在开店第一天就迎来了五万多顾客，这使得我也不由得开始对年轻人的”限量商品“抱有浓厚兴趣了。 ​Loft带给人的，是如\u0026rdquo;城市超市”般的功能美，它很好体现出“合理性至上”的原则。装饰性的物品被撕下，露出了建筑材料本来面目。而在这样一个纯粹而功能性的空间里，又如何能展现出其中的“乐趣”？这正是这次策划需要解答的。涩谷店的墙壁都是钢筋混凝土原本的面貌，这当然不是最初的设计，而是在经过多次商讨之后最终作出的决定：将建筑材料原原本本的展现出来，回归自然。我们告诉施工单位，墙壁涂抹了混凝土后就可以收工了，现场的工人们听后非常吃惊和抵触。 而事实上，裸露着管线的天花板有着抽象画般的形式，粗糙的混凝土墙也拥有漂亮的纹路和质地，他们是相当具有Loft感觉的。店铺的货架满满当当地向着天花板伸展而上，就连库存的商品也成了组成空间的重要角色。可以说Loft的这一设计和那些做作的百货商店装潢完全相左，它将原来绝不会示人的仓库几乎完全的展现在人们面前。 而在视觉策划上也是一样，它一反目前流行的后现代主义中间色，果断地使用了被百货商店和零售业视为禁忌的“铭黄”，更大胆地运用“大红”等醒目的原色。在散发着野性美的材料空间中，这鲜明锐利的黄色发挥出了生动的作用，立刻显现了现代主义的氛围。” ​\n9. 床之间和西洋的墙壁  如果说日本的床之间是严格选择而凝视于一点的艺术，那么西方的墙壁则集中了各种各样的视觉，是一种拼贴的美。 床之间就像是家里的一个小画廊，只需安上一幅挂轴，再在地板上搭配几个具有立体造型的物件。虽然说是几个物件，但最好还要一个重点，所以对所有的点都要进行严格的选择。 季节的变化，装饰品的由来典故、为客人准备的小心意、搭配的手法、对藏品的自豪等许多想法，由于要在床之间这个小画廊里进行简洁的展示，因而会被浓缩成一个一个点。而当天主人与客人的话题便会从床之间的艺术品开始，这是一个在第一时刻传达主人所拥有的教养及情绪感觉的地方。 在这一点上，西方的室内空间会带有些阿拉伯风格。相比较床之间的艺术所追求的孤立感，西方的墙壁会将很多的东西用同一感觉进行整合将人包围起来，墙壁上装满各种各样的艺术品、肖像画或风景画这类小小的绘画作品，还有那些具有纪念意味的东西，就像在这里展示着家庭的经历和故事，油彩、素描画、版画、照片、刺绣等各种制作方法和表现形式都在一面墙壁上构成了一个整体，不可思议的是竟然有一种调和的装置美术感。 ​\n10.浮世绘  浮世绘是日本的一种绘画艺术形式，起源于17世纪，主要描绘人们日常生活、风景、和戏剧。浮世绘常被认为专指彩色印刷的木版画（日语称为锦绘），但事实上也有手绘的作品。日本的浮世绘是在平民的爱戴下发展起来的，那时，歌舞伎与作为宫廷艺术的雅乐、作为武士家族的能乐就有着本质的不同，浮世绘也是如此，最初只是为了满足贫民世俗的好奇心。当时从中国传入的水墨画作为一种翻译型文化成为了知识分子修养的表现，而浮世绘却是与贫民的歌舞伎、游玩的欢乐场面紧密相连的，它是非常煽情的。师宣、春信、歌糜就是当时著名的浮世绘画师，可以说当时没有哪个画师没有描写过色情场面。 在江户时代，无论多么复杂的东西，绘画师都会将色彩的样本交给上色师进行参考。当作者田中一光来到工厂，将自己用绘图笔绘制的原画交给上色师时，突然恍然大悟。他们并不使用自己调好的颜色，而是每次用蓝色的时候就用一点点蓝颜料放在台面上，再用水刷毛将颜色舒展开，瞬间调出几乎没有偏差的中间色。他们早已练就了那种完全不需要思考的熟练手感。同时也深切的感受到，原来图画的生死都取决于上色师的手指，与其说他们是在上色还不如说是在绘画。 ​ ​ ​ 书的后半部分是朱鄂对田中一光的传记。可以看出，一位设计师，不是有些人认为的，两耳不闻窗外事，一心只走设计路的艺术魔，田中一光喜欢戏剧、音乐、舞蹈、做菜，并且他在这几方面都很擅长，据说，从他的工作室走出去了好多准新娘，姑娘们到了这里，多多少少都会几道拿手的好菜。他也好环球旅行，好奇心极强,一生未婚。 \u0026hellip;\u0026hellip; 还有许多日常的东西，就写到这里吧。 ​\n附录 ​ 第一章\n 无印良品考 我的二十一世纪 “传达”与“记录”的分离 海报的昌盛 文字与设计 图案与设计 单纯化与设计 海外声誉渐高的日本广告和设计 东方和西方的黄金感觉 一次性纸杯 用眼睛去发现森林 永远的琳派 宗达与设计 纹样美学 缟与色 白与黑中显现的红 饥饿与过饱 海报 日本 中国与汉字 民族的椅子 每日设计赏的四十年 木纹之美 琳派和设计 我眼中的任清 过剩包装 待客的美学 ​ 第二章 一个人的创想之旅 玻璃窗边的版面设计 三宅一生、高田贤三、森英惠 平面艺术的时间 书桌上的三个商标 年历的变迁 店铺设计 从平面艺术的“植物园”说起 通向“茶美会 然”之道 接近浮世绘 泰然的质感 ​ 第三章 我的古典 美丽而封闭的故乡 绢制樱花 来自日记 我的歌舞伎 俯瞰的风景 日本人的审美观 设计与日本文化 日本的城市与色彩 日本与平面设计 写乐的大首绘 信贵山的缘起 日本画的文学性 爵士乐与色彩 关于火 品尝设计 集中的美学 回想爵士乐 印象派的色彩 床之间和西洋的墙壁 在京都俵屋感受日式清凉 对于通俗的认识 后混合文化  ","title":"读懂《设计的觉醒》\n"},{"location":"项目/context_router","tags":["golang","router"],"text":"GitHub: https://github.com/ti/ctxrouter\nFeatures  Context Append on Current Function Best Performance (no regexp match) Wildcards Router Support (PathPrefix) Decode request body before business layer (JSON, xml or other) Decode request url before business layer Zero Garbage  Examples Basic Example package main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;strconv\u0026quot; ) //context style func (ctx *Context) Hello(id string) { //ctx.Request ... ctx.Writer.Write([]byte(\u0026quot;hello \u0026quot; + id)) } //normal style func NormalHello(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;hello \u0026quot; + ctxrouter.Params(r)[0])) } //func style func Hello(ctx *ctxrouter.Context, name string, id int) { ctx.Text(\u0026quot;hello \u0026quot; + name + \u0026quot;, id is \u0026quot; + strconv.Itoa(id)) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/basic/:name\u0026quot;, (*Context).Hello) r.Get(\u0026quot;/normal/:name\u0026quot;, NormalHello) r.Get(\u0026quot;/func/:name/:id\u0026quot;,Hello) r.Get(\u0026quot;/\u0026quot;, (*Context).Index) //auto decode url with string or int r.Get(\u0026quot;/basic/:name/json/:age\u0026quot;, (*Context).Json) //match path prefixes /all/*: r.All(\u0026quot;/basic/*path\u0026quot;,(*Context).All) //a simple func without implement ctxrouter.Context http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type Context struct { ctxrouter.Context } func (c *Context) Index() { c.Text(\u0026quot;index\u0026quot;) } func (c *Context) All(path string) { c.Text(\u0026quot;all router goes here \u0026quot; + path) } func (c *Context) Json(name string, age int) { type Person struct { Name string Age int } c.JSON(Person{Name:name,Age:age}) }  With Powerful Context //do something Workflow with ctx router package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) type Context struct { ctxrouter.Context Data map[string]string } func (c *Context) Start() { c.Data = make(map[string]string) c.Data[\u0026quot;context\u0026quot;] = \u0026quot;0\u0026quot; c.Step() } func (c *Context) Step() { c.Data[\u0026quot;context1\u0026quot;] = \u0026quot;1\u0026quot; c.End() } func (c *Context) End() { c.Data[\u0026quot;context2\u0026quot;] = \u0026quot;2\u0026quot; c.JSON(c.Data) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/context/\u0026quot;,(*Context).Start) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  Decode Request Before Business Layer package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) //decode request sample type User struct { Id int `json:\u0026quot;int\u0026quot;` Name string `json:\u0026quot;name\u0026quot;` } type UserContext struct { ctxrouter.Context Data *User } //Auto Decode Json or other request func (ctx *UserContext) DecodeRequest() error { ctx.Data = new(User) ctx.Context.Data = ctx.Data return ctx.Context.DecodeRequest() } func (ctx *UserContext) SayHello() { ctx.Text(\u0026quot;Hello \u0026quot;+ ctx.Data.Name) } func main() { r := ctxrouter.New() r.Post(\u0026quot;/users/hello\u0026quot;,(*UserContext).SayHello) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  curl -i -X POST \\ -H \u0026quot;Content-Type:application/json\u0026quot; \\ -d \\ '{\u0026quot;name\u0026quot;:\u0026quot;leenanxi\u0026quot;}' \\ 'http://localhost:8081/users/hello'  Normal HTTP Handler Alert: This is Not recommended if you start a new project.\npackage main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; ) func NormalHelloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;HELLO\u0026quot;)) } func NormalHandler(w http.ResponseWriter, r *http.Request) { params := ctxrouter.Params(r) w.Write([]byte(\u0026quot;Name:\u0026quot; + params[0] + \u0026quot;\\nAge:\u0026quot; + params[1] )) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/normal/hello\u0026quot;,NormalHelloHandler) r.Get(\u0026quot;/normal/v1/:name/:age\u0026quot;,NormalHandler) //support any http.Handler interface r.Get(\u0026quot;/404\u0026quot;,http.NotFoundHandler()) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  How Middleware X? The router is http.Handler, so you can chain any http.Handler compatible middleware before the router, for example http://www.gorillatoolkit.org/pkg/handlers\npackage main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;github.com/gorilla/handlers\u0026quot; \u0026quot;os\u0026quot; \u0026quot;net/http\u0026quot; ) //context style func (ctx *Context) Hello(name string) { ctx.Text(\u0026quot;hello \u0026quot; + name) } func main() { r := ctxrouter.New() r.Get(\u0026quot;/hello/:name\u0026quot;, (*Context).Hello) http.ListenAndServe(\u0026quot;:8081\u0026quot;, (handlers.LoggingHandler(os.Stdout, r))) } type Context struct { ctxrouter.Context }  Static Files package main import ( \u0026quot;github.com/ti/ctxrouter\u0026quot; \u0026quot;net/http\u0026quot; ) func main() { var dir = \u0026quot;/your/static/dir/path\u0026quot; r := ctxrouter.New() r.All(\u0026quot;/static/*path\u0026quot;,http.StripPrefix(\u0026quot;/static/\u0026quot;, http.FileServer(http.Dir(dir)))) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) }  Restful Api package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) func main() { r := ctxrouter.New() r.Get(\u0026quot;/apps\u0026quot;, (*AppContext).GetApps) r.Get(\u0026quot;/apps/:id\u0026quot;, (*AppContext).GetApp) r.Post(\u0026quot;/apps\u0026quot;, (*AppContext).PostApps) r.Patch(\u0026quot;/apps/:id\u0026quot;, (*AppContext).PatchApp) r.Put(\u0026quot;/apps/:id\u0026quot;, (*AppContext).PutApp) r.Delete(\u0026quot;/apps/:id\u0026quot;, (*AppContext).DeleteApp) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type AppContext struct { ctxrouter.Context } func (ctx *AppContext) GetApps() { ctx.Text(\u0026quot;get apps\u0026quot;) } func (ctx *AppContext) GetApp(id string) { ctx.Text(\u0026quot;get app \u0026quot; + id) } func (ctx *AppContext) PostApps() { ctx.Text(\u0026quot;post apps\u0026quot;) } func (ctx *AppContext) DeleteApp(id string) { ctx.Text(\u0026quot;delete app \u0026quot; + id) } func (ctx *AppContext) PutApp(id string) { ctx.Text(\u0026quot;put app \u0026quot; + id) } func (ctx *AppContext) PatchApp(id string) { ctx.Text(\u0026quot;patch app \u0026quot; + id) }  Full Example //full example with all features in one file, you can read sections above package main import ( \u0026quot;net/http\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;github.com/ti/ctxrouter\u0026quot; ) func main() { r := ctxrouter.New() r.Get(\u0026quot;/\u0026quot;, (*Controller).Index) r.Get(\u0026quot;/basic/:name\u0026quot;, (*Controller).Hello) //match path prefixes /all/*: r.All(\u0026quot;/basic/*path\u0026quot;,(*Controller).All) //auto decode url with string or int r.Get(\u0026quot;/basic/:name/json/:age\u0026quot;, (*Controller).Json) //a simple func without implement ctxrouter.Context r.Get(\u0026quot;/basic/:name/simple\u0026quot;,Simple) r.Post(\u0026quot;/users/hello\u0026quot;,(*UserContext).PrintHello) //do something Workflow with ctx router r.Get(\u0026quot;/context/\u0026quot;,(*Context).Start) r.Get(\u0026quot;/normal/hello\u0026quot;,NormalHelloHandler) r.Get(\u0026quot;/normal/v1/:name/:age\u0026quot;,NormalHandler) //support any http.Handler interface r.Get(\u0026quot;/404\u0026quot;,http.NotFoundHandler()) //static files var dir = \u0026quot;/your/static/dir/path\u0026quot; r.All(\u0026quot;/static/*path\u0026quot;,http.StripPrefix(\u0026quot;/static/\u0026quot;, http.FileServer(http.Dir(dir)))) http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } type Controller struct { ctxrouter.Context } func (c *Controller) Index() { c.Text(\u0026quot;index\u0026quot;) } func (c *Controller) Hello(name string) { fmt.Fprintln(c.Writer, \u0026quot;hello \u0026quot;+name) } func (c *Controller) All(path string) { c.Text(\u0026quot;all router goes here \u0026quot; + path) } //input json and output json func (c *Controller) Json(name string, age int) { type Person struct { Name string Age int } c.JSON(Person{Name:name,Age:age}) } func Simple(ctx *ctxrouter.Context, name string) { ctx.Text(\u0026quot;simple \u0026quot; + name) } //decode request sample type User struct { Id int `json:\u0026quot;int\u0026quot;` Name string `json:\u0026quot;name\u0026quot;` } type UserContext struct { ctxrouter.Context Data *User } //Auto Decode Json or other request func (ctx *UserContext) DecodeRequest() error{ ctx.Data = new(User) ctx.Context.Data = ctx.Data return ctx.Context.DecodeRequest() } func (ctx *UserContext) PrintHello() { ctx.Text(\u0026quot;Hello \u0026quot;+ ctx.Data.Name) } type Context struct { ctxrouter.Context Data map[string]string } func (c *Context) Start() { c.Data = make(map[string]string) c.Data[\u0026quot;context\u0026quot;] = \u0026quot;0\u0026quot; c.Step() } func (c *Context) Step() { c.Data[\u0026quot;context1\u0026quot;] = \u0026quot;1\u0026quot; c.End() } func (c *Context) End() { c.Data[\u0026quot;context2\u0026quot;] = \u0026quot;2\u0026quot; c.JSON(c.Data) } func NormalHelloHandler(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026quot;HELLO\u0026quot;)) } func NormalHandler(w http.ResponseWriter, r *http.Request) { //get router Params from \u0026quot;X-Ctxrouter-Params\u0026quot; without any extra function params := ctxrouter.Params(r) w.Write([]byte(\u0026quot;Name:\u0026quot; + params[0] + \u0026quot;\\nAge:\u0026quot; + params[1] )) }  Thanks  tree.go \u0026amp; tree_test.go is edited from httprouter https://github.com/julienschmidt/httprouter  ","title":"CtxRouter A High performance HTTP request router with Context\n"},{"location":"项目/nasync","tags":["golang"],"text":"a customizable async task pool for golang, (event bus, runtime)\ngithub: https://github.com/ti/nasync\nFetures  less memory more effective max gorutines and memory customizable more safe  Simple Usage nasync.Do(function)  Advanced Usage go get github.com/ti/nasync  import \u0026quot;github.com/ti/nasync\u0026quot; func main() { //new a async pool in max 1000 task in max 1000 gorutines async := nasync.New(1000,1000) defer async.Close() async.Do(doSometing,\u0026quot;hello word\u0026quot;) nasync.Do(func() { http.Get(\u0026quot;https://github.com/ti/\u0026quot;) }) } func doSometing(msg string) string{ return \u0026quot;i am done by \u0026quot; + msg }  WHY golang is something easy but fallible language, you may do this\nfunc yourfucntion() { go dosomething() // this will got error on high load }  you may get \u0026ldquo;too many open files\u0026rdquo; error, when your application in High load, so you need this, you can do any thing in async by this, it is trusty。your can use this for:\n http or file writer logging improve main thread speed limited background task pool  What if something callback ? import \u0026quot;github.com/ti/nasync\u0026quot; func main() { nasync.Do(func() { result := doSometing(\u0026quot;msg\u0026quot;) fmt.Println(\u0026quot;i am call back by \u0026quot;,result) }) } func doSometing(msg string) string{ return \u0026quot;i am done by \u0026quot; + msg }  ","title":"NASYNC \n"},{"location":"开发/redis事务介绍","tags":["redis"],"text":"写在前面：一般情况下，我们不建议将数据可用性内容放在redis中进行操作，例如转账，关系建立等，redis被认为是一个较不可靠的数据库，一般用作数据缓存，pubsub机制，session保持等使用场景，本文介绍redis事务，并不代表它可以处理常见的事务需求。常见nosql中事务处理机制类似，可做参考。\n相信学过MySQL等其他数据库的同学对事务这个词都不陌生，事务表示的是一组动作，这组动作要么全部执行，要么全部不执行。为什么会有这样的需求呢？看看下面的场景：\n  微博是一个弱关系型社交网络，用户之间有关注和被关注两种关系，比如两个用户A和B，如果A关注B，则B的粉丝中就应该有A。关注这个动作需要两个步骤完成：在A的关注者中添加B；在B的粉丝中添加A。 这两个动作要么都执行成功，要么都不执行。否则就可能会出现A关注了B，但是B的粉丝中没有A的不可容忍的情况。 转账汇款，假设现在有两个账户A和B，现在需要将A中的一万块大洋转到B的账户中，这个动作也需要两个步骤完成：从A的账户中划走一万块；在B的账户中增加一万块。这两个动作要么全部执行成功，要么全部不执行，否则自会有人问候你的！！！   Redis作为一种高效的分布式数据库，同样支持事务。\nRedis事务 Redis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。Redis事务的实现需要用到** MULTI 和 EXEC 两个命令，事务开始的时候先向Redis服务器发送 MULTI 命令，然后依次发送需要在本次事务中处理的命令，最后再发送 EXEC **命令表示事务命令结束。\n举个例子，使用redis-cli连接redis，然后在命令行工具中输入如下命令：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set url http://qifuguang.me QUEUED 127.0.0.1:6379\u0026gt; set title winwill2012 QUEUED 127.0.0.1:6379\u0026gt; set desc java QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) OK 3) OK 127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; get url \u0026quot;http://qifuguang.me\u0026quot; 127.0.0.1:6379\u0026gt; get title \u0026quot;winwill2012\u0026quot; 127.0.0.1:6379\u0026gt; get desc \u0026quot;java\u0026quot; 127.0.0.1:6379\u0026gt;  从输出中可以看到，当输入MULTI命令后，服务器返回OK表示事务开始成功，然后依次输入需要在本次事务中执行的所有命令，每次输入一个命令服务器并不会马上执行，而是返回”QUEUED”，这表示命令已经被服务器接受并且暂时保存起来，最后输入EXEC命令后，本次事务中的所有命令才会被依次执行，可以看到最后服务器一次性返回了三个OK，这里返回的结果与发送的命令是按顺序一一对应的，这说明这次事务中的命令全都执行成功了。\n再举个例子，在命令行工具中输入如下命令：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set a a QUEUED 127.0.0.1:6379\u0026gt; sett b b (error) ERR unknown command 'sett' 127.0.0.1:6379\u0026gt; set c c QUEUED 127.0.0.1:6379\u0026gt; EXEC (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379\u0026gt; get a (nil) 127.0.0.1:6379\u0026gt; get b (nil) 127.0.0.1:6379\u0026gt; get c (nil) 127.0.0.1:6379\u0026gt;  和前面的例子一样，先输入MULTI最后输入EXEC表示中间的命令属于一个事务，不同的是中间输入的命令有一个错误(set写成了sett)，这样因为有一个错误的命令导致事务中的其他命令都不执行了(通过后续的get命令可以验证)，可见事务中的所有命令式同呼吸共命运的。\n如果客户端在发送EXEC命令之前断线了，则服务器会清空事务队列，事务中的所有命令都不会被执行。而一旦客户端发送了EXEC命令之后，事务中的所有命令都会被执行，即使此后客户端断线也没关系，因为服务器已经保存了事务中的所有命令。\n除了保证事务中的所有命令要么全执行要么全不执行外，Redis的事务还能保证一个事务中的命令依次执行而不会被其他命令插入。试想一个客户端A需要执行几条命令，同时客户端B发送了几条命令，如果不使用事务，则客户端B的命令有可能会插入到客户端A的几条命令中，如果想避免这种情况发生，也可以使用事务。\nRedis事务错误处理 如果一个事务中的某个命令执行出错，Redis会怎样处理呢？要回答这个问题，首先要搞清楚是什么原因导致命令执行出错：\n语法错误 就像上面的例子一样，语法错误表示命令不存在或者参数错误 这种情况需要区分Redis的版本，Redis 2.6.5之前的版本会忽略错误的命令，执行其他正确的命令，2.6.5之后的版本会忽略这个事务中的所有命令，都不执行，就比如上面的例子(使用的Redis版本是2.8的)\n运行错误 运行错误表示命令在执行过程中出现错误，比如用GET命令获取一个散列表类型的键值。 这种错误在命令执行之前Redis是无法发现的，所以在事务里这样的命令会被Redis接受并执行。如果食物里有一条命令执行错误，其他命令依旧会执行（包括出错之后的命令）。比如下例：\n127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set key 1 QUEUED 127.0.0.1:6379\u0026gt; SADD key 2 QUEUED 127.0.0.1:6379\u0026gt; set key 3 QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) (error) WRONGTYPE Operation against a key holding the wrong kind of value 3) OK 127.0.0.1:6379\u0026gt; get key \u0026quot;3\u0026quot;  Redis中的事务并没有关系型数据库中的事务回滚(rollback)功能，因此使用者必须自己收拾剩下的烂摊子。不过由于Redis不支持事务回滚功能，这也使得Redis的事务简洁快速。\n回顾上面两种类型的错误，语法错误完全可以在开发的时候发现并作出处理，另外如果能很好地规划Redis数据的键的使用，也是不会出现命令和键不匹配的问题的。\nWATCH命令 从上面的例子我们可以看到，事务中的命令要全部执行完之后才能获取每个命令的结果，但是如果一个事务中的命令B依赖于他上一个命令A的结果的话该怎么办呢？就比如说实现类似java中的i++的功能，先要获取当前值，才能在当前值的基础上做加一操作。这种场合仅仅使用上面介绍的MULTI和EXEC是不能实现的，因为MULTI和EXEC中的命令是一起执行的，并不能将其中一条命令的执行结果作为另一条命令的执行参数，所以这个时候就需要引进Redis事务家族中的另一成员：WATCH命令\n换个角度思考上面说到的实现i++的方法，可以这样实现：\n  监控i的值，保证i的值不被修改 获取i的原值 如果过程中i的值没有被修改，则将当前的i值+1，否则不执行   这样就能够避免竞态条件，保证i++能够正确执行。\nWATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，EXEC命令执行完之后被监控的键会自动被UNWATCH）\n举个例子：\n127.0.0.1:6379\u0026gt; set mykey 1 OK 127.0.0.1:6379\u0026gt; WATCH mykey OK 127.0.0.1:6379\u0026gt; set mykey 2 OK 127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; set mykey 3 QUEUED 127.0.0.1:6379\u0026gt; EXEC (nil) 127.0.0.1:6379\u0026gt; get mykey \u0026quot;2\u0026quot; 127.0.0.1:6379\u0026gt;  上面的例子中，首先设置mykey的键值为1，然后使用WATCH命令监控mykey，随后更改mykey的值为2，然后进入事务，事务中设置mykey的值为3，然后执行EXEC运行事务中的命令，最后使用get命令查看mykey的值，发现mykey的值还是2，也就是说事务中的命令根本没有执行（因为WATCH监控mykey的过程中，mykey被修改了，所以随后的事务便会被取消）。\n有了WATCH命令，我们就可以自己实现i++功能了，伪代码如下：\ndef incr($key): WATCH $key $value = GET $key if not $value $value = 0 $value = $value + 1 MULTI SET $key $value result = EXEC return result[0]  因为EXEC返回的是多行字符串，使用result[0]表示返回值的第一个字符串。\n注意：由于WATCH命令的作用只是当被监控的键被修改后取消之后的事务，并不能保证其他客户端不修改监控的值，所以当EXEC命令执行失败之后需要手动重新执行整个事务。\n执行EXEC命令之后会取消监控使用WATCH命令监控的键，如果不想执行事务中的命令，也可以使用UNWATCH命令来取消监控。\n声明 原创文章，转载请注明出处，本文链接：http://qifuguang.me/2015/09/30/Redis事务介绍/\n","title":"Redis事务介绍\n"},{"location":"开发/redis高并发问题","tags":["redis"],"text":"Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：\n1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。\n2.服务器角度，利用setnx实现锁。\n对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。\nSETNX命令（SET if Not eXists） 语法： SETNX key value\n功能： 将 key 的值设为 value ，当且仅当 key 不存在；若给定的 key 已经存在，则 SETNX 不做任何动作。\n时间复杂度： O(1) 返回值： 设置成功，返回 1 。 设置失败，返回 0 。\n模式：将 SETNX 用于加锁(locking)\nSETNX 可以用作加锁原语(locking primitive)。比如说，要对关键字(key) foo 加锁，客户端可以尝试以下方式：\nSETNX lock.foo 如果 SETNX 返回 1 ，说明客户端已经获得了锁， key 设置的unix时间则指定了锁失效的时间。之后客户端可以通过 DEL lock.foo 来释放锁。\n如果 SETNX 返回 0 ，说明 key 已经被其他客户端上锁了。如果锁是非阻塞(non blocking lock)的，我们可以选择返回调用，或者进入一个重试循环，直到成功获得锁或重试超时(timeout)。\n但是已经证实仅仅使用SETNX加锁带有竞争条件，在特定的情况下会造成错误。\n处理死锁(deadlock)\n上面的锁算法有一个问题：如果因为客户端失败、崩溃或其他原因导致没有办法释放锁的话，怎么办？\n这种状况可以通过检测发现——因为上锁的 key 保存的是 unix 时间戳，假如 key 值的时间戳小于当前的时间戳，表示锁已经不再有效。\n但是，当有多个客户端同时检测一个锁是否过期并尝试释放它的时候，我们不能简单粗暴地删除死锁的 key ，再用 SETNX 上锁，因为这时竞争条件(race condition)已经形成了：\nC1 和 C2 读取 lock.foo 并检查时间戳， SETNX 都返回 0 ，因为它已经被 C3 锁上了，但 C3 在上锁之后就崩溃(crashed)了。 C1 向 lock.foo 发送 DEL 命令。 C1 向 lock.foo 发送 SETNX 并成功。 C2 向 lock.foo 发送 DEL 命令。 C2 向 lock.foo 发送 SETNX 并成功。 出错：因为竞争条件的关系，C1 和 C2 两个都获得了锁。\n幸好，以下算法可以避免以上问题。来看看我们聪明的 C4 客户端怎么办：\nC4 向 lock.foo 发送 SETNX 命令。 因为崩溃掉的 C3 还锁着 lock.foo ，所以 Redis 向 C4 返回 0 。 C4 向 lock.foo 发送 GET 命令，查看 lock.foo 的锁是否过期。如果不，则休眠(sleep)一段时间，并在之后重试。 另一方面，如果 lock.foo 内的 unix 时间戳比当前时间戳老，C4 执行以下命令： GETSET lock.foo 因为 GETSET 的作用，C4 可以检查看 GETSET 的返回值，确定 lock.foo 之前储存的旧值仍是那个过期时间戳，如果是的话，那么 C4 获得锁。 如果其他客户端，比如 C5，比 C4 更快地执行了 GETSET 操作并获得锁，那么 C4 的 GETSET 操作返回的就是一个未过期的时间戳(C5 设置的时间戳)。C4 只好从第一步开始重试。 注意，即便 C4 的 GETSET 操作对 key 进行了修改，这对未来也没什么影响。\n这里假设锁key对应的value没有实际业务意义，否则会有问题，而且其实其value也确实不应该用在业务中。\n为了让这个加锁算法更健壮，获得锁的客户端应该常常检查过期时间以免锁因诸如 DEL 等命令的执行而被意外解开，因为客户端失败的情况非常复杂，不仅仅是崩溃这么简单，还可能是客户端因为某些操作被阻塞了相当长时间，紧接着 DEL 命令被尝试执行(但这时锁却在另外的客户端手上)。\nGETSET命令 语法： GETSET key value\n功能： 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。当 key 存在但不是字符串类型时，返回一个错误。\n时间复杂度： O(1)\n返回值： 返回给定 key 的旧值；当 key 没有旧值时，也即是， key 不存在时，返回 nil 。\n","title":"Redis并发问题\n"},{"location":"开发/mysql索引背后的数据结构及算法原理","tags":["mysql","算法"],"text":"MySQL索引背后的数据结构及算法原理 本文以MySQL数据库为研究对象，讨论与数据库索引相关的一些话题。特别需要说明的是，MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。为了避免混乱，本文将只关注于BTree索引，因为这是平常使用MySQL时主要打交道的索引，至于哈希索引和全文索引本文暂不讨论。\n文章主要内容分为三个部分。\n第一部分主要从数据结构及算法理论层面讨论MySQL数据库索引的数理基础。\n第二部分结合MySQL数据库中MyISAM和InnoDB数据存储引擎中索引的架构实现讨论聚集索引、非聚集索引及覆盖索引等话题。\n第三部分根据上面的理论基础，讨论MySQL中高性能使用索引的策略。\n数据结构及算法基础 索引的本质 MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。\n我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。\n看一个例子：\n\n图1\n图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2n)O(log2n)的复杂度内获取到相应数据。\n虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。\nB-Tree和B+Tree 目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。\nB-Tree 为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：\nd为大于1的一个正整数，称为B-Tree的度。\nh为一个正整数，称为B-Tree的高度。\n每个非叶子节点由n-1个key和n个指针组成，其中d\u0026lt;=n\u0026lt;=2d。\n每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。\n所有叶节点具有相同的深度，等于树高h。\nkey和指针互相间隔，节点两端是指针。\n一个节点中的key从左到右非递减排列。\n所有节点组成树结构。\n每个指针要么为null，要么指向另外一个节点。\n如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)v(key1)，其中v(key1)v(key1)为node的第一个key的值。\n如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)v(keym)，其中v(keym)v(keym)为node的最后一个key的值。\n如果某个指针在节点node的左右相邻key分别是keyikeyi和keyi+1keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)v(keyi+1)且大于v(keyi)v(keyi)。\n图2是一个d=2的B-Tree示意图。\n\n图2\n由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：\nBTree_Search(node, key) { if(node == null) return null; foreach(node.key) { if(node.key[i] == key) return node.data[i]; if(node.key[i] \u0026gt; key) return BTree_Search(point[i]-\u0026gt;node); } return BTree_Search(point[i+1]-\u0026gt;node); } data = BTree_Search(root, my_key);  关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为\nlogd((N+1)/2)logd((N+1)/2)\n，检索一个key，其查找节点个数的渐进复杂度为\nO(logdN)O(logdN)\n。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。\n另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。\nB+Tree B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。\n与B-Tree相比，B+Tree有以下不同点：\n每个节点的指针上限为2d而不是2d+1。\n内节点不存储data，只存储key；叶子节点不存储指针。\n图3是一个简单的B+Tree示意。\n\n图3\n由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。\n一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。\n带有顺序访问指针的B+Tree 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。\n\n图4\n如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。\n这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。\n为什么使用B-Tree（B+Tree） 上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。\n一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。\n主存存取原理 目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。\n\n图5\n从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。\n主存的存取过程如下：\n当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。\n写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。\n这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。\n磁盘存取原理 上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。\n图6是磁盘的整体结构示意图。\n\n图6\n一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。\n图7是磁盘结构的示意图。\n\n图7\n盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。\n当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。\n局部性原理与磁盘预读 由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：\n当一个数据被用到时，其附近的数据也通常会马上被使用。\n程序运行期间所需要的数据通常比较集中。\n由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。\n预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\nB-/+Tree索引的性能分析 到这里终于可以分析B-/+Tree索引的性能了。\n上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。\nB-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n综上所述，用B-Tree作为索引结构效率是非常高的。\n而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。\n上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：\ndmax=floor(pagesize/(keysize+datasize+pointsize))dmax=floor(pagesize/(keysize+datasize+pointsize))\nfloor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。\n这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。\nMySQL索引实现 在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。\nMyISAM索引实现 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：\n\n图8\n这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：\n\n图9\n同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。\nMyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。\nInnoDB索引实现 虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。\n第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。\n\n图10\n图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。\n第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引：\n\n图11\n这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。\n下一章将具体讨论这些与索引有关的优化策略。\n索引使用策略及优化 MySQL的优化主要分为结构优化（Scheme optimization）和查询优化（Query optimization）。本章讨论的高性能索引策略主要属于结构优化范畴。本章的内容完全基于上文的理论基础，实际上一旦理解了索引背后的机制，那么选择高性能的策略就变成了纯粹的推理，并且可以理解这些策略背后的逻辑。\n示例数据库 为了讨论索引策略，需要一个数据量不算小的数据库作为示例。本文选用MySQL官方文档中提供的示例数据库之一：employees。这个数据库关系复杂度适中，且数据量较大。下图是这个数据库的E-R关系图（引用自MySQL官方手册）：\n\n图12\nMySQL官方文档中关于此数据库的页面为http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法，如果有兴趣导入此数据库到自己的MySQL可以参考文中内容。\n最左前缀原理与相关优化 高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。\n这里先说一下联合索引的概念。在上文中，我们都是假设索引只引用了单个的列，实际上，MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组，其中各个元素均为数据表的一列，实际上要严格定义索引需要用到关系代数，但是这里我不想讨论太多关系代数的话题，因为那样会显得很枯燥，所以这里就不再做严格定义。另外，单列索引可以看成联合索引元素数为1的特例。\n以employees.titles表为例，下面先查看其上都有哪些索引：\nSHOW INDEX FROM employees.titles; +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type | +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+ | titles | 0 | PRIMARY | 1 | emp_no | A | NULL | | BTREE | | titles | 0 | PRIMARY | 2 | title | A | NULL | | BTREE | | titles | 0 | PRIMARY | 3 | from_date | A | 443308 | | BTREE | | titles | 1 | emp_no | 1 | emp_no | A | 443308 | | BTREE | +--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+  从结果中可以到titles表的主索引为，还有一个辅助索引。为了避免多个索引使事情变复杂（MySQL的SQL优化器在多索引时行为比较复杂），这里我们将辅助索引drop掉：\nALTER TABLE employees.titles DROP INDEX emp_no;  这样就可以专心分析索引PRIMARY的行为了。\n情况一：全列匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26'; +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+ | 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | | +----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+  很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：\nEXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26' AND emp_no='10001' AND title='Senior Engineer';+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+| 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | |+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+  效果是一样的。\n情况二：最左前缀匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001';+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+  当查询条件精确匹配索引的左边连续一个或几个列时，如或，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。\n情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'; +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+ | 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where | +----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+  此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。\n首先我们看下title一共有几种不同的值：\nSELECT DISTINCT(title) FROM employees.titles; +--------------------+ | title | +--------------------+ | Senior Engineer | | Staff | | Engineer | | Senior Staff | | Assistant Engineer | | Technique Leader | | Manager | +--------------------+  只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager') AND from_date='1986-06-26'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 7 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较：\nSHOW PROFILES; +----------+------------+-------------------------------------------------------------------------------+ | Query_ID | Duration | Query | +----------+------------+-------------------------------------------------------------------------------+ | 10 | 0.00058000 | SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'| | 11 | 0.00052500 | SELECT * FROM employees.titles WHERE emp_no='10001' AND title IN ... | +----------+------------+-------------------------------------------------------------------------------+  “填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。\n情况四：查询条件没有指定索引第一列。 EXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26'; +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+ | 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where | +----+-------------+--------+------+---------------+------+---------+------+--------+-------------+  由于不是最左前缀，索引这样的查询显然用不到索引。\n情况五：匹配某列的前缀字符串。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 56 | NULL | 1 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  此时可以用到索引，但是如果通配符不是只出现在末尾，则无法使用索引。（原文表述有误，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀）\n情况六：范围查询。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no \u0026lt; '10010' and title='Senior Engineer'; +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ | 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where | +----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no \u0026lt; '10010'AND title='Senior Engineer'AND from_date BETWEEN '1986-01-01' AND '1986-12-31';+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  可以看到索引对第二个范围索引无能为力。这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询：\nEXPLAIN SELECT * FROM employees.titlesWHERE emp_no BETWEEN '10001' AND '10010'AND title='Senior Engineer'AND from_date BETWEEN '1986-01-01' AND '1986-12-31';+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 16 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+  看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。\n情况七：查询条件中含有函数或表达式。 很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior';+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where |+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+  虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1='10000';+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+| 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where |+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+  显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。\n索引选择性与前缀索引 既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。\n第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。\n另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：\nIndex Selectivity = Cardinality / #T\n显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，上文用到的employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：\nSELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;+-------------+| Selectivity |+-------------+| 0.0000 |+-------------+  title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。\n有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。\n从图12可以看到employees表只有一个索引，那么如果我们想按名字搜索一个人，就只能全表扫描了：\nEXPLAIN SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido';+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+| 1 | SIMPLE | employees | ALL | NULL | NULL | NULL | NULL | 300024 | Using where |+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+  如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建或，看下两个索引的选择性：\nSELECT count(DISTINCT(first_name))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.0042 |+-------------+SELECT count(DISTINCT(concat(first_name, last_name)))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.9313 |+-------------+  显然选择性太低，选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如，看看其选择性：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.7879 |+-------------+  选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：\nSELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;+-------------+| Selectivity |+-------------+| 0.9007 |+-------------+  这时选择性已经很理想了，而这个索引的长度只有18，比短了接近一半，我们把这个前缀索引 建上：\nALTER TABLE employees.employeesADD INDEX `first_name_last_name4` (first_name, last_name(4));  此时再执行一遍按名字查询，比较分析一下与建索引前的结果：\nSHOW PROFILES;+----------+------------+---------------------------------------------------------------------------------+| Query_ID | Duration | Query |+----------+------------+---------------------------------------------------------------------------------+| 87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' || 90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' |+----------+------------+---------------------------------------------------------------------------------+  性能的提升是显著的，查询速度提高了120多倍。\n前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。\nInnoDB的主键选择与插入优化 在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。\n经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。\n上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。\n如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：\n\n图13\n这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。\n如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：\n\n图14\n此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。\n因此，只要可以，请尽量在InnoDB上采用自增字段做主键。\n后记 这篇文章断断续续写了半个月，主要内容就是上面这些了。不可否认，这篇文章在一定程度上有纸上谈兵之嫌，因为我本人对MySQL的使用属于菜鸟级别，更没有太多数据库调优的经验，在这里大谈数据库索引调优有点大言不惭。就当是我个人的一篇学习笔记了。\n其实数据库索引调优是一项技术活，不能仅仅靠理论，因为实际情况千变万化，而且MySQL本身存在很复杂的机制，如查询优化策略和各种引擎的实现差异等都会使情况变得更加复杂。但同时这些理论是索引调优的基础，只有在明白理论的基础上，才能对调优策略进行合理推断并了解其背后的机制，然后结合实践中不断的实验和摸索，从而真正达到高效使用MySQL索引的目的。\n另外，MySQL索引及其优化涵盖范围非常广，本文只是涉及到其中一部分。如与排序（ORDER BY）相关的索引优化及覆盖索引（Covering index）的话题本文并未涉及，同时除B-Tree索引外MySQL还根据不同引擎支持的哈希索引、全文索引等等本文也并未涉及。如果有机会，希望再对本文未涉及的部分进行补充吧。\n","title":"MySQL索引背后的数据结构及算法原理"}]